---
title: "data_clean"
format: html
editor: visual
---

# Final Project: Alternate Runs Data-set

**Experimental design:** Â Switching every 4 trials in an alternating runs manner (no cues). Total of 8 experimental blocks were intended, but 60 subjects saw only 7 blocks. Across these blocks counterbalancing of four conditions: Both tasks unambiguous (1), both tasks ambiguous (4), shape ambiguous when irrelevant, color always ambiguous (2), shape always ambiguous, color unambiguous when irrelevant (2)

### **What the variables mean:**

-   block: 0 for practice, there are a total of 8 blocks per part and each block consists of 112 trials. So 896 trials per participant over all 7 blocks (not counting practice)

-   bal: counterbalancing of conditions across blocks

-   x, y, c2: irrelevant (already taken out)

-   cycle: counting within full alternating cycle (8), switch at 1 and 5

-   task: 1=shape, 2=color

-   dimshape=specific shapes--4=neutral

-   dimcolor=specific color--4=neutral

-   correct: correct response (i.e., value of the currently relevant task dimension)

-   error: 0 = no error, 1 = yes error

-   response: actual response

-   RT: or response time

### Import data-set and some packages

```{r}
#open neccesary packages here
library(tidyverse)
library(janitor)
library(readr)
library(rio)
library(psych) #generate metrix w scatterplot and cor
#import dataset
AlternateRuns <- read_csv("AlternateRuns.csv")
view(AlternateRuns)
```

## Clean-Data

### Rename Columns to Understand Better

```{r}
#rename columns to understand better
alt_run <- AlternateRuns %>% 
  rename(dimshape = dim1, dimcolor = dim2, RT = time, correct = cor, response = res)
alt_run

```

### Replace Numeric Values w Character Strings for Task and Error

```{r}
# replace numeric values w character strings for task and error
alt_run_1 <- alt_run %>% mutate(task = recode(task, `1` = "shape", `2` = 'color')) %>% 
  mutate(error = recode(error, `0` = "no", `1` = 'yes'))
alt_run_1
```

### Remove Practice Trials in Block Variable + pivot func

```{r}
#removing practice trials from our df
alt_run <- alt_run %>% 
  filter(block != 0) %>% 
  print()

#use pivot long and/or? wide here with some key variables we want to look at. may need to alter df to turn some 1s and 0s in columns to be names... (correct, incorrect or color, shape). fix code below...

# alt_run %>% 
#   pivot_wider(names_from = task, values_from = block)
```

### Determine and Remove Outliers (RT way...)

```{r}


alt_run %>% 
  arrange(desc(RT))
#there are quite a few RTs that get up to 10000 ms for one trial... determine outliers

#need to group by participant to get overall mean and sd for reaction time to determine which subjects to omit from the dataset. Thinking that 3 SDs above or below the mean is a  good criterion for outliers. 

#WHAT TO DO: zscore on each seq postiion x switch x abiguity on RT then zscore on each block (to account for some participants only doing 7 instaead of 8 blocks) 

#cycles of 4 mutate to make a new group for easier cycle analysis

#mean_rt_per <- alt_run %>% 
 # group_by(id) %>% 
 # summarize(mean(RT, na.rm = TRUE)) %>% 
 # print()

#sd_rt_per <- alt_run %>% 
 # group_by(id) %>% 
 # summarize(sd(RT, na.rm = TRUE)) %>% 
#  print()

#z_scores <- (alt_run$RT - mean_rt_per)/sd_rt_per

#alt_run_r <- alt_run %>%
 # group_by(id) %>% 
  #mutate(z_scores = z_scores) %>% 
  #select(z_scores, RT, id) %>% 
 # print()


#alt_run %>% 
 # group_by(z_scores, id) %>% 
 # print()

#outliers_alt <- alt_run$RT[abs(z_scores) > 3]
  #tibble(outliers_alt)


```

### Determine and Remove Outliers (Error way...)

```{r}
# we are testing for accuracy, so we need at least 80% accuracy in all trials per participant 
#determine 80% accuracy 
crit <- 896 - (896 * .8)
crit # need at least 179 out of 896 trials to be correct, denoted by 0 in error col
sum_er <- alt_run %>% 
  group_by(id) %>% 
summarize(sum = sum(error)) %>% 
  print()

sum_er <- sum_er %>% 
  mutate(outlier_er =  (sum > crit)) %>% 
  print()
  
sum_er <- sum_er %>% 
  filter(outlier_er == !FALSE) %>% 
  print()
view(sum_er) #two people fall below 80% accuracy

#removing those outliers here 

alt_run_e <- alt_run %>% 
  filter(id != 70, id != 87)
view(alt_run_e)

```

## Descriptive Graphs

### 1. Histogram of RT

```{r}
mean_rt <- mean(alt_run$RT, na.rm = TRUE)
mean_rt
sd_rt <-  sd(alt_run$RT, na.rm = TRUE)


alt_run %>% 
  ggplot(aes(x=RT)) +
  geom_histogram(aes(y = after_stat(density)), fill = 'darkgray', color = 'darkblue') +
  geom_vline(aes(xintercept = mean_rt) , color = 'red', linetype = 'dashed', size = 1.5) +
    theme_minimal() +
  stat_function(fun = dnorm, args = list(mean = mean_rt, sd = sd_rt) ,  col = 'darkred', size = 1.5) +
    labs(x= 'Response Times (ms)', y= 'Density', title = 'Histogram of Response Times', subtitle = 'The mean and normal density curve of RTs') 
```

### 2. Boxplot of RT

```{r}
#boxplot of all RTs regardless of task
boxplot(alt_run_1$RT)

#boxplot of RTs when doing shape task
boxplot_s <- filter(alt_run_1, task == 'shape')
boxplot(boxplot_s$RT)

#boxplot of RTs when doing color task
boxplot_c <- filter(alt_run_1, task == 'color')
boxplot(boxplot_c$RT)
```

### 3. Correlations

```{r}
cor_alt <- alt_run %>% 
  select(RT, cycle, task)
  cor(cor_alt, use = "complete.obs")
```

```{r}
#is there a correlation between response times and error rate? also note: used the psych package to generate this
  alt_run %>% 
    select(RT, error) %>%
    pairs.panels(lm = TRUE)
```

**5. Scatterplot in select**

**6. Selecting : already did?**

**7. Pivoting**

**8. Descriptives table**
